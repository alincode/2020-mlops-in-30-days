# 透過 apt-get 指令建構 Tensorflow Serving 環境

在前一篇我們有提到，只要取得 save_model 後，我們就可以開始跟 Model 互動，這部分 Tensorflow 已經幫我們想好了，我們可以使用 `Tensorflow Serving` 來幫我們自動產生 RESTful API 或 gRPC API。

<https://www.tensorflow.org/tfx/guide/serving>

```
# 呼叫 API 範例
curl http://localhost:8501/v1/models/saved_model_counter
```

### 安裝 TensorFlow ModelServer

```
echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -
```

```
apt-get update && apt-get install tensorflow-model-server
```

### 啟動 TensorFlow ModelServer

透過指令啟動 TensorFlow ModelServer

#### 語法

```
tensorflow_model_server --port=8500 --rest_api_port=8501 \
  --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME}
```

#### 範例

```
tensorflow_model_server --port=8500 --rest_api_port=8501 \
  --model_name=my_model --model_base_path=/models/my_model
```

#### 參數說明

- gRPC 對外的 port 是 8500
- REST API 對外的 port 是 8501
- MODEL_NAME：指定的 Model 名稱，這個範例指定的名稱是 `my_model`，如果沒指定則預設為 `model`。
- MODEL_BASE_PATH：指定的 MODEL_BASE_PATH 資料夾放置位置，這個範例指定的資料夾位置是 `/models/my_model`，如果沒指定則預設為 `/models` 資料夾。
