# 解析 Tensorflow Serving 的 Docker file

docker hub: <https://hub.docker.com/r/tensorflow/serving/tags/>

```
git clone https://github.com/tensorflow/serving
cd serving/tensorflow_serving/tools/docker
```

以 ubuntu 18.04 為映像檔基底

```
FROM ubuntu:18.04
```

略過一些預設的套件

```
--no-install-recommends
```

安裝 Tensorflow Serving Serving 套件，複製 `/usr/local/bin/tensorflow_model_server` 到 `/usr/bin/tensorflow_model_server`。

```
COPY --from=build_image /usr/local/bin/tensorflow_model_server /usr/bin/tensorflow_model_server
```

指定 MODEL_BASE_PATH 位置

```
ENV MODEL_BASE_PATH=/models
```

建立資料夾

```
RUN mkdir -p ${MODEL_BASE_PATH}
```

設定模組名稱

```
ENV MODEL_NAME=model
```

產生 `tf_serving_entrypoint.sh` 檔

```
RUN echo '#!/bin/bash \n\n\
tensorflow_model_server --port=8500 --rest_api_port=8501 \
--model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \
"$@"' > /usr/bin/tf_serving_entrypoint.sh \
&& chmod +x /usr/bin/tf_serving_entrypoint.sh
```

啟動 `/usr/bin/tf_serving_entrypoint.sh`

```
ENTRYPOINT ["/usr/bin/tf_serving_entrypoint.sh"]
```

> ENTRYPOINT：和 CMD 一樣，用來設定映像檔啟動 Container 時要執行的指令，但不同的是，ENTRYPOINT 一定會被執行，而不會有像 CMD 覆蓋的情況發生。

### 完整的 Dockerfile 檔案

```
ARG TF_SERVING_VERSION=latest
ARG TF_SERVING_BUILD_IMAGE=tensorflow/serving:${TF_SERVING_VERSION}-devel

FROM ${TF_SERVING_BUILD_IMAGE} as build_image
FROM ubuntu:18.04

ARG TF_SERVING_VERSION_GIT_BRANCH=master
ARG TF_SERVING_VERSION_GIT_COMMIT=head

LABEL maintainer="gvasudevan@google.com"
LABEL tensorflow_serving_github_branchtag=${TF_SERVING_VERSION_GIT_BRANCH}
LABEL tensorflow_serving_github_commit=${TF_SERVING_VERSION_GIT_COMMIT}

RUN apt-get update && apt-get install -y --no-install-recommends \
        ca-certificates \
        && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install TF Serving pkg
COPY --from=build_image /usr/local/bin/tensorflow_model_server /usr/bin/tensorflow_model_server

# Expose ports
# gRPC
EXPOSE 8500

# REST
EXPOSE 8501

# Set where models should be stored in the container
ENV MODEL_BASE_PATH=/models
RUN mkdir -p ${MODEL_BASE_PATH}

# The only required piece is the model name in order to differentiate endpoints
ENV MODEL_NAME=model

# Create a script that runs the model server so we can use environment variables
# while also passing in arguments from the docker command line
RUN echo '#!/bin/bash \n\n\
tensorflow_model_server --port=8500 --rest_api_port=8501 \
--model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} \
"$@"' > /usr/bin/tf_serving_entrypoint.sh \
&& chmod +x /usr/bin/tf_serving_entrypoint.sh

ENTRYPOINT ["/usr/bin/tf_serving_entrypoint.sh"]
```

<https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile>

### 參考來源

- [Dockerfile - ENV 與 ARG 參數](https://peihsinsu.gitbooks.io/docker-note-book/content/dockerfile-env-vs-arg.html)
