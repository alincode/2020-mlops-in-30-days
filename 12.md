# 訓練 Model

- tf.compat.v1.train.GradientDescentOptimizer
- minimize
- run

```
train_step = tf.compat.v1.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
train_step.run(feed_dict={x: batch[0], y_: batch[1]})
```

### 範例

```python
mnist = mnist_input_data.read_data_sets(FLAGS.work_dir, one_hot=True)
sess = tf.compat.v1.InteractiveSession()
serialized_tf_example = tf.compat.v1.placeholder(tf.string, name='tf_example')
feature_configs = {
    'x': tf.io.FixedLenFeature(shape=[784], dtype=tf.float32),
}
tf_example = tf.io.parse_example(serialized_tf_example, feature_configs)
x = tf.identity(tf_example['x'], name='x')  # use tf.identity() to assign name
y_ = tf.compat.v1.placeholder('float', shape=[None, 10])
w = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
sess.run(tf.compat.v1.global_variables_initializer())
y = tf.nn.softmax(tf.matmul(x, w) + b, name='y')
cross_entropy = -tf.math.reduce_sum(y_ * tf.math.log(y))
train_step = tf.compat.v1.train.GradientDescentOptimizer(0.01).minimize(
    cross_entropy)
values, indices = tf.nn.top_k(y, 10)
table = lookup_ops.index_to_string_table_from_tensor(
    tf.constant([str(i) for i in range(10)]))
prediction_classes = table.lookup(tf.dtypes.cast(indices, tf.int64))
for _ in range(FLAGS.training_iteration):
  batch = mnist.train.next_batch(50)
  train_step.run(feed_dict={x: batch[0], y_: batch[1]})
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.math.reduce_mean(tf.cast(correct_prediction, 'float'))
print('training accuracy %g' % sess.run(
    accuracy, feed_dict={
        x: mnist.test.images,
        y_: mnist.test.labels
    }))
```

<https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py>