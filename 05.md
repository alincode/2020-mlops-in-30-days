# 透過 Docker 來建構 Tensorflow Serving

前一篇我們有提到怎麼用 `apt-get` 來安裝 `tensorflow-model-server`，但使用 Tensorflow 官方包好的 Docker Image，則會是更簡單的一種方式。我們又如何使用 Docker Image 來建構 Tensorflow Serving，總共會有三個步驟：

1. 安裝 TensorFlow 服務
1. 開始運行 TensorFlow 服務
1. 在 TensorFlow Serving 中向您的模型提出請求

### 安裝 TensorFlow 服務

透過 Docker Hub 下載 TensorFlow Serving 的 image

```sh
docker pull tensorflow/serving
```

### 開始運行 TensorFlow 服務

從 Git repo 下載預先訓練的 Model

```sh
git clone https://github.com/tensorflow/serving
```

啟動 TensorFlow Serving 服務，並指定對外開放 port 號，及指定預存模組放置的位置。

```sh
TESTDATA="$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata"

docker run -t --rm -p 8501:8501 \
    -v "$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two" \
    -e MODEL_NAME=half_plus_two \
    tensorflow/serving &
```

### 從 TensorFlow Serving 取得預測結果

透過 API 跟 Model 溝通，取得 Model 預測後的資料。

```sh
curl -d '{"instances": [1.0, 2.0, 5.0]}' \
    -X POST http://localhost:8501/v1/models/half_plus_two:predict
```

回傳的結果範例 => `{ "predictions": [2.5, 3.0, 4.5] }`

## 參考資料

- <https://hub.docker.com/r/tensorflow/serving/tags/>
- <https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/docker.md>
- <https://www.tensorflow.org/tfx/guide/serving>
